{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as sq\n",
    "\n",
    "engine = sq.create_engine(\"postgresql://localhost/crime2021\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statement = \"\"\"select nibrs_offense.offense_id, a.county_name, ni.data_year, ni.incident_hour, ni.incident_date, nbm.bias_id, nlt.location_name, n.offense_name, n.offense_code, n.offense_category_name, nwt.weapon_code from nibrs_offense\n",
    "                JOIN nibrs_bias_motivation nbm on nibrs_offense.offense_id = nbm.offense_id\n",
    "                left join nibrs_weapon nw on nibrs_offense.offense_id = nw.offense_id\n",
    "                left join nibrs_weapon_type nwt on nw.weapon_id = nwt.weapon_id\n",
    "                join nibrs_incident ni on nibrs_offense.incident_id = ni.incident_id\n",
    "                join nibrs_bias_list nbl on nbm.bias_id = nbl.bias_id\n",
    "                join agencies a on ni.agency_id = a.agency_id\n",
    "                join nibrs_location_type nlt on nibrs_offense.location_id = nlt.location_id\n",
    "                join nibrs_offense_type n on nibrs_offense.offense_code = n.offense_code;\"\"\"\n",
    "result = conn.execute(statement)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEX_CRIME_CODE = [\"11\", \"36\", \"90H\"]            # rape, sodomy, SA with object, fondling, incest, stat. rape, peeping tom - offense_code\n",
    "FIREARM_CODE   = [\"11\", \"12\", \"13\", \"14\", \"15\"] # NIBRS_WEAPON_TYPE, firearm, handgun, rifle, shotgun, other firearm - weapon_code\n",
    "HATE_CODE      = \"88\"                           # if result contains this number, it is NOT a hate crime - bias_id\n",
    "\n",
    "def create_incident_time_dict(incident: dict) -> dict:\n",
    "    time_dict = dict()\n",
    "    time_dict[\"inc_hour\"] = incident[\"incident_hour\"]\n",
    "    time_dict[\"inc_day\"] = incident[\"incident_date\"].day\n",
    "    time_dict[\"inc_month\"] = incident[\"incident_date\"].month\n",
    "    time_dict[\"inc_year\"] = incident[\"incident_date\"].year\n",
    "    return time_dict\n",
    "\n",
    "def awful_array_string_checker(string: str, arr: list) -> bool: # I feel like there's a better built in function for this... oh well\n",
    "    for e in arr:\n",
    "        if e in string:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_codes(incident: dict, finished_dict: dict) -> dict:\n",
    "    finished_dict['gun_violence'] = False\n",
    "    finished_dict['sex_crime']    = False\n",
    "    finished_dict['hate_crime']   = False\n",
    "\n",
    "    if awful_array_string_checker(incident['offense_code'], SEX_CRIME_CODE):\n",
    "        finished_dict['sex_crime'] = True\n",
    "    if (wc := incident['weapon_code']) and awful_array_string_checker(wc, FIREARM_CODE):\n",
    "        finished_dict['gun_violence'] = True\n",
    "    if HATE_CODE not in str(incident['bias_id']):\n",
    "        finished_dict['hate_crime'] = True\n",
    "\n",
    "    return finished_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_results(res):\n",
    "    import time\n",
    "    start = time.time()\n",
    "    res_dict = dict()\n",
    "    seen = dict()\n",
    "    i = 0\n",
    "    for u in res.all():\n",
    "        #if i == 1: break;\n",
    "        incident_dict = dict(u)\n",
    "\n",
    "        finished_incident_dict = dict()\n",
    "        # add timing\n",
    "        time_dict = create_incident_time_dict(incident_dict)\n",
    "        finished_incident_dict[\"inc_time\"] = time_dict\n",
    "\n",
    "        # check crime, offense, bias codes to generate boolean\n",
    "        finished_incident_dict = check_codes(incident_dict, finished_incident_dict)\n",
    "\n",
    "        finished_incident_dict[\"crime_desc\"] = incident_dict['offense_name']\n",
    "        finished_incident_dict['off_code'] = incident_dict['offense_code']\n",
    "        finished_incident_dict['loc_id'] = incident_dict['location_name']\n",
    "        # strip this to make index\n",
    "        finished_incident_dict['county'] = incident_dict['county_name']\n",
    "        finished_incident_dict['id'] = incident_dict['offense_id']\n",
    "\n",
    "        # if another incident exists with another offender, keep code flags\n",
    "        if incident_dict['offense_id'] in seen:\n",
    "            continue\n",
    "        else:\n",
    "            seen[incident_dict['offense_id']] = incident_dict\n",
    "\n",
    "        res_dict[i] = finished_incident_dict\n",
    "        i+=1\n",
    "    # import pprint\n",
    "    # pprint.pprint(res_dict)\n",
    "    end = time.time()\n",
    "    print(f\"Done processing {len(res_dict)} rows in {end-start} seconds\")\n",
    "    return res_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multiple_county_handler(entry, f_handler, idx, county_sep: str):\n",
    "    county = entry['county']\n",
    "    # print(f\"Handling multiple counties {county}\")\n",
    "\n",
    "    curr_idx = county.index(county_sep, idx)+2\n",
    "    next_idx = -1\n",
    "\n",
    "    try:\n",
    "        next_idx = county.index(county_sep, curr_idx)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if next_idx != -1:\n",
    "        idx = next_idx\n",
    "\n",
    "    index_dict = dict()\n",
    "    sub_index_dict = dict()\n",
    "    curr_county = county[curr_idx: next_idx if next_idx != -1 else len(county)]\n",
    "    sub_index_dict['_index'] = curr_county.replace(\" \", \",\").lower()\n",
    "    # sub_index_dict['dupe'] = True\n",
    "    old_county = entry.pop('county')\n",
    "    # del entry['county']\n",
    "\n",
    "    sub_index_dict['_id'] = entry['id']\n",
    "    # del entry['id']\n",
    "    old_id = entry.pop('id')\n",
    "\n",
    "    index_dict['index'] = sub_index_dict\n",
    "\n",
    "    metadata = json.dumps(index_dict)\n",
    "    data = json.dumps(entry)\n",
    "\n",
    "    entry['county'] = old_county\n",
    "    entry['id'] = old_id\n",
    "\n",
    "    f_handler.write(f'{metadata}\\n')\n",
    "    f_handler.write(f'{data}\\n')\n",
    "\n",
    "    return idx\n",
    "\n",
    "def write_data(res_dict: dict, county_sep: str):\n",
    "    import time\n",
    "    start = time.time()\n",
    "    lines = 0\n",
    "    chunks = 0\n",
    "    import json\n",
    "    import uuid\n",
    "    f = open(f'data/{uuid.uuid4()}.json', 'w', encoding='utf-8')\n",
    "    for entry in res_dict.values():\n",
    "        index_dict = dict()\n",
    "        sub_index_dict = dict()\n",
    "        county = entry['county'] # type: str\n",
    "        index_found = 0\n",
    "        for i in range(county.count(county_sep)): # multiple counties check\n",
    "            index_found = multiple_county_handler(entry, f, index_found, county_sep)\n",
    "\n",
    "        stopping_point = len(county) if county_sep not in county else county.index(county_sep)\n",
    "        county = county[0:stopping_point]\n",
    "        county = county.replace(\" \", \"_\").lower()\n",
    "        sub_index_dict['_index'] = county\n",
    "        del entry['county']\n",
    "\n",
    "        sub_index_dict['_id'] = entry['id']\n",
    "        del entry['id']\n",
    "\n",
    "        index_dict['index'] = sub_index_dict\n",
    "\n",
    "        metadata = json.dumps(index_dict)\n",
    "        data = json.dumps(entry)\n",
    "\n",
    "        f.write(f'{metadata}\\n')\n",
    "        f.write(f'{data}\\n')\n",
    "        lines +=1\n",
    "        if lines % 200 == 0:\n",
    "            f.close()\n",
    "            f = open(f'data/{uuid.uuid4()}.json', 'w', encoding='utf-8')\n",
    "            chunks += 1\n",
    "    f.close()\n",
    "    stop = time.time()\n",
    "    print(f'Finished writing {lines} entries to {chunks} chunks in {stop-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as sq\n",
    "\n",
    "engine = sq.create_engine(\"postgresql://localhost/crime2021\")\n",
    "conn = engine.connect()\n",
    "statement_2021 = \"\"\"select nibrs_offense.offense_id, a.county_name, ni.data_year, ni.incident_hour, ni.incident_date, nbm.bias_id, nlt.location_name, n.offense_name, n.offense_code, n.offense_category_name, nwt.weapon_code from nibrs_offense\n",
    "                JOIN nibrs_bias_motivation nbm on nibrs_offense.offense_id = nbm.offense_id\n",
    "                left join nibrs_weapon nw on nibrs_offense.offense_id = nw.offense_id\n",
    "                left join nibrs_weapon_type nwt on nw.weapon_id = nwt.weapon_id\n",
    "                join nibrs_incident ni on nibrs_offense.incident_id = ni.incident_id\n",
    "                join nibrs_bias_list nbl on nbm.bias_id = nbl.bias_id\n",
    "                join agencies a on ni.agency_id = a.agency_id\n",
    "                join nibrs_location_type nlt on nibrs_offense.location_id = nlt.location_id\n",
    "                join nibrs_offense_type n on nibrs_offense.offense_code = n.offense_code;\"\"\"\n",
    "result_2021 = conn.execute(statement_2021)\n",
    "conn.close()\n",
    "\n",
    "engine = sq.create_engine(\"postgresql://localhost/crime\")\n",
    "conn = engine.connect()\n",
    "statement_all_other_years = \"\"\"select nibrs_offense.offense_id, a.county_name, ni.data_year, ni.incident_hour, ni.incident_date, nbl.bias_code as bias_id, nlt.location_name, n.offense_name, n.offense_code, n.offense_category_name, nwt.weapon_code from nibrs_offense\n",
    "                                JOIN nibrs_bias_motivation nbm on nibrs_offense.offense_id = nbm.offense_id\n",
    "                                left join nibrs_weapon nw on nibrs_offense.offense_id = nw.offense_id\n",
    "                                left join nibrs_weapon_type nwt on nw.weapon_id = nwt.weapon_id\n",
    "                                join nibrs_incident ni on nibrs_offense.incident_id = ni.incident_id\n",
    "                                join nibrs_bias_list nbl on nbm.bias_id = nbl.bias_id\n",
    "                                join agencies a on ni.agency_id = a.agency_id\n",
    "                                join nibrs_location_type nlt on nibrs_offense.location_id = nlt.location_id\n",
    "                                join nibrs_offense_type n on nibrs_offense.offense_type_id = n.offense_type_id;\"\"\"\n",
    "result_others = conn.execute(statement_all_other_years)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test code for faster filtering\n",
    "# import sqlalchemy as sq\n",
    "\n",
    "# def execute_statement(engine_url: str, statement: str):\n",
    "#     engine = sq.create_engine(engine_url)\n",
    "#     with engine.connect() as conn:\n",
    "#         result = conn.execute(statement)\n",
    "#     return result\n",
    "\n",
    "# statement_2021 = \"\"\"select nibrs_offense.offense_id, a.county_name, ni.data_year, ni.incident_hour, ni.incident_date, nbm.bias_id, nlt.location_name, n.offense_name, n.offense_code, n.offense_category_name, nwt.weapon_code from nibrs_offense\n",
    "#                 JOIN nibrs_bias_motivation nbm on nibrs_offense.offense_id = nbm.offense_id\n",
    "#                 left join nibrs_weapon nw on nibrs_offense.offense_id = nw.offense_id\n",
    "#                 left join nibrs_weapon_type nwt on nw.weapon_id = nwt.weapon_id\n",
    "#                 join nibrs_incident ni on nibrs_offense.incident_id = ni.incident_id\n",
    "#                 join nibrs_bias_list nbl on nbm.bias_id = nbl.bias_id\n",
    "#                 join agencies a on ni.agency_id = a.agency_id\n",
    "#                 join nibrs_location_type nlt on nibrs_offense.location_id = nlt.location_id\n",
    "#                 join nibrs_offense_type n on nibrs_offense.offense_code = n.offense_code;\"\"\"\n",
    "# result_2021 = execute_statement(\"postgresql://localhost/crime2021\", statement_2021)\n",
    "\n",
    "# statement_all_other_years = \"\"\"select nibrs_offense.offense_id, a.county_name, ni.data_year, ni.incident_hour, ni.incident_date, nbl.bias_code as bias_id, nlt.location_name, n.offense_name, n.offense_code, n.offense_category_name, nwt.weapon_code from nibrs_offense\n",
    "#                                 JOIN nibrs_bias_motivation nbm on nibrs_offense.offense_id = nbm.offense_id\n",
    "#                                 left join nibrs_weapon nw on nibrs_offense.offense_id = nw.offense_id\n",
    "#                                 left join nibrs_weapon_type nwt on nw.weapon_id = nwt.weapon_id\n",
    "#                                 join nibrs_incident ni on nibrs_offense.incident_id = ni.incident_id\n",
    "#                                 join nibrs_bias_list nbl on nbm.bias_id = nbl.bias_id\n",
    "#                                 join agencies a on ni.agency_id = a.agency_id\n",
    "#                                 join nibrs_location_type nlt on nibrs_offense.location_id = nlt.location_id\n",
    "#                                 join nibrs_offense_type n on nibrs_offense.offense_type_id = n.offense_type_id;\"\"\"\n",
    "# result_others = execute_statement(\"postgresql://localhost/crime\", statement_all_other_years)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing 390517 rows in 2.1734089851379395 seconds\n",
      "Finished writing 390517 entries to 1952 chunks in 2.406928062438965 seconds\n",
      "Done processing 1625858 rows in 13.483729839324951 seconds\n",
      "Finished writing 1625858 entries to 8129 chunks in 9.574924945831299 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import shutil\n",
    "shutil.rmtree('data', ignore_errors=True)\n",
    "import os\n",
    "os.mkdir('data')\n",
    "res_2021_dict = process_results(result_2021)\n",
    "write_data(res_2021_dict, \", \")\n",
    "res_others_dict = process_results(result_others)\n",
    "write_data(res_others_dict, \"; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os._exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
